# ðŸ—ºï¸ Landmark Recognition in Azerbaijan â€” Deep Learning Project

This project showcases a deep learning pipeline I developed for classifying famous landmarks in Azerbaijan using **transfer learning with ResNet-18**.  
It was part of my Deep Learning course (CSCI 4701), and I worked on it as a core contributor in a two-person team.

---

## ðŸš€ Overview

- ðŸ“š **Course**: CSCI 4701 â€“ Deep Learning  
- ðŸ§  **Model**: ResNet-18 (pretrained on ImageNet)  
- ðŸ›ï¸ **Classes**:
  - Maiden Tower  
  - Deniz Mall  
  - Shirvanshahlar Palace  
  - DÉ™dÉ™ Qorqud Monument  
  - Heydar Aliyev Center  

---

## ðŸ“ Dataset

The dataset consists of 738 manually collected images (train/test split) and was published on [Hugging Face](https://huggingface.co/datasets/khaleed-mammad/azerbaijan-landmarks-dataset).  
We collected images from different times of day (day/night) and converted them from `.heic` to `.jpg`.

- ðŸ“¦ **Train**: ~586 images  
- ðŸ“¦ **Test**: ~152 images  
- ðŸ–¼ï¸ Format: JPG  
- ðŸ—‚ï¸ Structure: 5 folders per split (one per class)

---

## ðŸ§° My Contributions

This project was a great opportunity to work end-to-end on a deep learning application.  
Hereâ€™s what I personally worked on:

- ðŸ–¼ï¸ **Data Preprocessing & Organization**: Converted image formats, organized into `train/` and `test/`, helped upload to Hugging Face.
- ðŸ§± **Code Modularization**: Wrote `data_loader.py`, `model.py`, and `utils.py` for clean and reusable architecture.
- ðŸ§ª **Training Support**: Assisted with training baseline and augmented models, tuning, and testing.
- ðŸ“Š **Result Analysis**: Helped compare performance metrics, visualize results, and draw conclusions.

---

## ðŸ§  Model Details

- ðŸ” **Backbone**: ResNet-18 (frozen)
- ðŸ§© **Custom Head**: Final FC layer adapted for 5 classes
- ðŸŽ¯ **Loss**: CrossEntropyLoss  
- âš™ï¸ **Optimizer**: Adam (LR = 0.0005)  
- ðŸ§´ **Regularization**:
  - Dropout: `p=0.3`
  - Weight Decay: `1e-5`
- ðŸŒ€ **Data Augmentation**:
  - RandomResizedCrop, HorizontalFlip, ColorJitter, Rotation

---

## ðŸ“Š Results

| Model               | Train Accuracy | Test Accuracy |
|--------------------|----------------|---------------|
| Baseline (no aug)  | 94.37%         | 98.68%        |
| Augmented          | 86.86%         | 92.76%        |

> **Takeaway**: While augmentation improved generalization, the dataset's quality already gave very strong performance without it.